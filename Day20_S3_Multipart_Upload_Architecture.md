# Block File Uploads: How Dropbox & Netflix Upload 5TB Files to S3
### Day 20 of 50 - System Design Interview Preparation Series

**By Sunchit Dudeja**

---

## ğŸ¯ Welcome to Day 20!

Yesterday, we explored Bloom Filters for email uniqueness. Today, we dive into a critical infrastructure pattern: **How do applications like Dropbox, Netflix, and Google Drive upload massive files (100MB to 5TB) reliably to cloud storage?**

> "The secret isn't uploading one giant file. It's splitting it into chunks, uploading in parallel, and letting the cloud assemble them server-side."

---

## ğŸ¤” THE PROBLEM WITH LARGE FILE UPLOADS

### The Challenge

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              THE LARGE FILE UPLOAD NIGHTMARE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   Scenario: User uploads 2GB video file                          â”‚
â”‚                                                                  â”‚
â”‚   TRADITIONAL APPROACH (Single PUT):                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Client â”€â”€â”€â”€â”€â”€â”€â”€ 2GB in one request â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Server  â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   Problems:                                                      â”‚
â”‚   âŒ Network drops at 1.8GB â†’ Start over from 0                 â”‚
â”‚   âŒ 30-minute upload â†’ Connection timeout                      â”‚
â”‚   âŒ Server memory â†’ OOM with concurrent uploads                â”‚
â”‚   âŒ Progress bar â†’ All or nothing                              â”‚
â”‚   âŒ Single point of failure â†’ No parallelism                   â”‚
â”‚                                                                  â”‚
â”‚   MULTIPART APPROACH (Chunked Upload):                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Client â”€â”¬â”€ 100MB â”€â–¶ S3  â† Parallel!                    â”‚  â”‚
â”‚   â”‚          â”œâ”€ 100MB â”€â–¶ S3                                  â”‚  â”‚
â”‚   â”‚          â”œâ”€ 100MB â”€â–¶ S3                                  â”‚  â”‚
â”‚   â”‚          â””â”€ ...    â”€â–¶ S3                                  â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  S3: Assembles all parts into final object              â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   Benefits:                                                      â”‚
â”‚   âœ… Network drops at 1.8GB â†’ Resume from part 18               â”‚
â”‚   âœ… 4 parallel uploads â†’ 4x faster                             â”‚
â”‚   âœ… Server never sees data â†’ Scalable                          â”‚
â”‚   âœ… Progress bar â†’ Per-part tracking                           â”‚
â”‚   âœ… S3 assembles â†’ No re-upload                                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ HIGH-LEVEL ARCHITECTURE

### The Hybrid Client-Backend-S3 Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              S3 MULTIPART UPLOAD - ARCHITECTURE                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚  CLIENT  â”‚      â”‚   BACKEND    â”‚      â”‚   AWS S3     â”‚     â”‚
â”‚   â”‚ (Browser â”‚â—„â”€â”€â”€â”€â–¶â”‚   SERVICE    â”‚â—„â”€â”€â”€â”€â–¶â”‚              â”‚     â”‚
â”‚   â”‚  / App)  â”‚      â”‚ (Credentials)â”‚      â”‚              â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚        â”‚                                         â–²              â”‚
â”‚        â”‚                                         â”‚              â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€ DIRECT UPLOAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                  (via Presigned URLs)                           â”‚
â”‚                                                                  â”‚
â”‚   KEY INSIGHT:                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Backend handles: Credentials, URLs, Completion          â”‚  â”‚
â”‚   â”‚  Client handles:  Chunking, Parallel Upload, Progress    â”‚  â”‚
â”‚   â”‚  S3 handles:      Storage, Assembly, Integrity           â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  Backend NEVER sees file data â†’ Infinitely scalable!     â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Presigned URLs?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              WHY PRESIGNED URLs?                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   WITHOUT PRESIGNED URLs:                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Option A: Expose AWS credentials to client             â”‚  â”‚
â”‚   â”‚            â†’ SECURITY DISASTER! âŒ                       â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  Option B: Proxy all data through backend               â”‚  â”‚
â”‚   â”‚            â†’ Backend becomes bottleneck! âŒ              â”‚  â”‚
â”‚   â”‚            â†’ Memory exhaustion with large files! âŒ      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   WITH PRESIGNED URLs:                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  1. Backend generates time-limited signed URL           â”‚  â”‚
â”‚   â”‚  2. URL contains: bucket, key, expiry, signature        â”‚  â”‚
â”‚   â”‚  3. Client uploads DIRECTLY to S3 with this URL         â”‚  â”‚
â”‚   â”‚  4. No credentials exposed, no backend proxy            â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  âœ… SECURE + SCALABLE                                    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   Presigned URL Example:                                         â”‚
â”‚   https://bucket.s3.amazonaws.com/video.mp4                     â”‚
â”‚   ?X-Amz-Algorithm=AWS4-HMAC-SHA256                             â”‚
â”‚   &X-Amz-Credential=AKIAIOSFODNN7EXAMPLE...                     â”‚
â”‚   &X-Amz-Date=20240115T120000Z                                  â”‚
â”‚   &X-Amz-Expires=3600                                            â”‚
â”‚   &X-Amz-Signature=fe5f80f77d5fa3beca038a248f...                â”‚
â”‚                                                                  â”‚
â”‚   Valid for 1 hour, only for specified operation               â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ THE 6-STEP WORKFLOW

### Complete Interaction Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              6-STEP MULTIPART UPLOAD WORKFLOW                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   CLIENT              BACKEND              AWS S3                â”‚
â”‚     â”‚                    â”‚                    â”‚                  â”‚
â”‚     â”‚ â”€â”€â”€â”€ STEP 1 â”€â”€â”€â”€â”€â”€â–¶â”‚                    â”‚                  â”‚
â”‚     â”‚ POST /upload/init  â”‚                    â”‚                  â”‚
â”‚     â”‚ {fileName, size}   â”‚                    â”‚                  â”‚
â”‚     â”‚                    â”‚ â”€â”€â”€â”€ STEP 2 â”€â”€â”€â”€â”€â”€â–¶â”‚                  â”‚
â”‚     â”‚                    â”‚ CreateMultipart    â”‚                  â”‚
â”‚     â”‚                    â”‚ Upload             â”‚                  â”‚
â”‚     â”‚                    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                  â”‚
â”‚     â”‚                    â”‚     UploadId       â”‚                  â”‚
â”‚     â”‚                    â”‚                    â”‚                  â”‚
â”‚     â”‚                    â”‚ Generate Presigned â”‚                  â”‚
â”‚     â”‚                    â”‚ URLs for each part â”‚                  â”‚
â”‚     â”‚â—€â”€â”€â”€â”€ STEP 3 â”€â”€â”€â”€â”€â”€â”€â”‚                    â”‚                  â”‚
â”‚     â”‚ {uploadId, urls[]} â”‚                    â”‚                  â”‚
â”‚     â”‚                    â”‚                    â”‚                  â”‚
â”‚     â”‚ Split file into    â”‚                    â”‚                  â”‚
â”‚     â”‚ chunks locally     â”‚                    â”‚                  â”‚
â”‚     â”‚                    â”‚                    â”‚                  â”‚
â”‚     â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• STEP 4 â•â•â•â•â•â•â•â•â–¶â”‚                  â”‚
â”‚     â”‚   PUT Part 1 (Direct via Presigned URL) â”‚                  â”‚
â”‚     â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â–¶â”‚                  â”‚
â”‚     â”‚   PUT Part 2 (Parallel!)                â”‚                  â”‚
â”‚     â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â–¶â”‚                  â”‚
â”‚     â”‚   PUT Part N                            â”‚                  â”‚
â”‚     â”‚â—€â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚                  â”‚
â”‚     â”‚   ETags for each part                   â”‚                  â”‚
â”‚     â”‚                    â”‚                    â”‚                  â”‚
â”‚     â”‚ â”€â”€â”€â”€ STEP 5 â”€â”€â”€â”€â”€â”€â–¶â”‚                    â”‚                  â”‚
â”‚     â”‚ POST /upload/done  â”‚                    â”‚                  â”‚
â”‚     â”‚ {uploadId, parts[]}â”‚                    â”‚                  â”‚
â”‚     â”‚                    â”‚ â”€â”€â”€â”€ STEP 6 â”€â”€â”€â”€â”€â”€â–¶â”‚                  â”‚
â”‚     â”‚                    â”‚ CompleteMultipart  â”‚                  â”‚
â”‚     â”‚                    â”‚ Upload             â”‚                  â”‚
â”‚     â”‚                    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚                  â”‚
â”‚     â”‚                    â”‚   Final Object     â”‚                  â”‚
â”‚     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Created!         â”‚                  â”‚
â”‚     â”‚      SUCCESS!      â”‚                    â”‚                  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ STEP-BY-STEP IMPLEMENTATION

### Step 1: Client Initiates Upload

```javascript
// Client-side: Request to start upload
async function initiateUpload(file) {
    const response = await fetch('/api/upload/initiate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
            fileName: file.name,
            fileSize: file.size,
            contentType: file.type
        })
    });
    
    return await response.json();
    // Returns: { uploadId, presignedUrls, key }
}
```

### Step 2: Backend Creates Multipart Upload in S3

```java
// Backend: Spring Boot Controller
@PostMapping("/api/upload/initiate")
public UploadInitResponse initiateUpload(@RequestBody UploadRequest request) {
    // 1. Create multipart upload in S3
    CreateMultipartUploadRequest createRequest = CreateMultipartUploadRequest.builder()
        .bucket(bucketName)
        .key(request.getFileName())
        .contentType(request.getContentType())
        .build();
    
    CreateMultipartUploadResponse response = s3Client.createMultipartUpload(createRequest);
    String uploadId = response.uploadId();
    
    // 2. Calculate number of parts
    long partSize = 10 * 1024 * 1024; // 10MB chunks
    int totalParts = (int) Math.ceil((double) request.getFileSize() / partSize);
    
    // 3. Generate presigned URLs for each part
    List<PresignedUrl> presignedUrls = new ArrayList<>();
    for (int partNumber = 1; partNumber <= totalParts; partNumber++) {
        UploadPartRequest uploadPartRequest = UploadPartRequest.builder()
            .bucket(bucketName)
            .key(request.getFileName())
            .uploadId(uploadId)
            .partNumber(partNumber)
            .build();
        
        UploadPartPresignRequest presignRequest = UploadPartPresignRequest.builder()
            .signatureDuration(Duration.ofHours(1))
            .uploadPartRequest(uploadPartRequest)
            .build();
        
        PresignedUploadPartRequest presigned = s3Presigner.presignUploadPart(presignRequest);
        presignedUrls.add(new PresignedUrl(partNumber, presigned.url().toString()));
    }
    
    return new UploadInitResponse(uploadId, presignedUrls, request.getFileName());
}
```

### Step 3 & 4: Client Chunks and Uploads in Parallel

```javascript
// Client-side: Parallel chunk upload
const CHUNK_SIZE = 10 * 1024 * 1024; // 10MB
const CONCURRENCY = 4; // 4 parallel uploads

async function uploadFile(file, initResponse) {
    const { uploadId, presignedUrls, key } = initResponse;
    const totalParts = presignedUrls.length;
    const completedParts = [];
    
    // Upload parts with controlled concurrency
    for (let i = 0; i < totalParts; i += CONCURRENCY) {
        const batch = presignedUrls.slice(i, i + CONCURRENCY);
        
        const batchPromises = batch.map(async ({ partNumber, url }) => {
            const start = (partNumber - 1) * CHUNK_SIZE;
            const end = Math.min(start + CHUNK_SIZE, file.size);
            const chunk = file.slice(start, end);
            
            // Upload with retry logic
            const etag = await uploadPartWithRetry(url, chunk, 3);
            
            completedParts.push({ PartNumber: partNumber, ETag: etag });
            updateProgress(completedParts.length, totalParts);
        });
        
        await Promise.all(batchPromises);
    }
    
    // Sort by part number for completion
    completedParts.sort((a, b) => a.PartNumber - b.PartNumber);
    
    return { uploadId, key, parts: completedParts };
}

async function uploadPartWithRetry(url, chunk, maxRetries) {
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
        try {
            const response = await fetch(url, {
                method: 'PUT',
                body: chunk,
                headers: { 'Content-Type': 'application/octet-stream' }
            });
            
            if (!response.ok) throw new Error(`HTTP ${response.status}`);
            
            // ETag is returned in response header
            return response.headers.get('ETag');
        } catch (error) {
            if (attempt === maxRetries) throw error;
            // Exponential backoff
            await new Promise(r => setTimeout(r, 1000 * Math.pow(2, attempt)));
        }
    }
}
```

### Step 5 & 6: Complete the Multipart Upload

```java
// Backend: Complete the upload
@PostMapping("/api/upload/complete")
public UploadCompleteResponse completeUpload(@RequestBody CompleteRequest request) {
    List<CompletedPart> completedParts = request.getParts().stream()
        .map(p -> CompletedPart.builder()
            .partNumber(p.getPartNumber())
            .eTag(p.getETag())
            .build())
        .collect(Collectors.toList());
    
    CompleteMultipartUploadRequest completeRequest = CompleteMultipartUploadRequest.builder()
        .bucket(bucketName)
        .key(request.getKey())
        .uploadId(request.getUploadId())
        .multipartUpload(CompletedMultipartUpload.builder()
            .parts(completedParts)
            .build())
        .build();
    
    CompleteMultipartUploadResponse response = s3Client.completeMultipartUpload(completeRequest);
    
    return new UploadCompleteResponse(
        response.location(),
        response.eTag(),
        response.key()
    );
}
```

---

## ğŸ”§ S3 INTERNAL OPERATIONS

### What Happens Inside S3

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              S3 INTERNAL PROCESSING                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   STEP 1: CreateMultipartUpload                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  â€¢ Generates unique UploadId (UUID)                      â”‚  â”‚
â”‚   â”‚  â€¢ Creates metadata entry in S3 index                    â”‚  â”‚
â”‚   â”‚  â€¢ Allocates temporary storage space                     â”‚  â”‚
â”‚   â”‚  â€¢ NO data transfer yet                                  â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   STEP 2: UploadPart (for each part)                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  â€¢ Receives: PUT /bucket/key?partNumber=1&uploadId=xyz  â”‚  â”‚
â”‚   â”‚  â€¢ Validates: UploadId exists, PartNumber 1-10000       â”‚  â”‚
â”‚   â”‚  â€¢ Stores in TEMPORARY location (not final bucket)      â”‚  â”‚
â”‚   â”‚  â€¢ Computes MD5 hash of content                         â”‚  â”‚
â”‚   â”‚  â€¢ Returns ETag = "md5hash" (quoted!)                    â”‚  â”‚
â”‚   â”‚  â€¢ Updates metadata: {PartNumber, ETag, Size, Location} â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  Parts can be uploaded in ANY order!                     â”‚  â”‚
â”‚   â”‚  Parts can be OVERWRITTEN (same PartNumber)!             â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   Temporary Storage:                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  UploadId: VXBsb2FkSWQtMTIz...                          â”‚  â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚   â”‚  Part 1: ETag="abc123", Size=10MB, Loc=/tmp/p1          â”‚  â”‚
â”‚   â”‚  Part 2: ETag="def456", Size=10MB, Loc=/tmp/p2          â”‚  â”‚
â”‚   â”‚  Part 3: ETag="ghi789", Size=10MB, Loc=/tmp/p3          â”‚  â”‚
â”‚   â”‚  Part 4: ETag="jkl012", Size=5MB,  Loc=/tmp/p4 (last)   â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   STEP 3: CompleteMultipartUpload (THE MAGIC!)                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  1. Receives: POST with ordered {PartNumber, ETag} list â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  2. VALIDATES:                                           â”‚  â”‚
â”‚   â”‚     â€¢ All parts exist                                    â”‚  â”‚
â”‚   â”‚     â€¢ ETags match (integrity check!)                     â”‚  â”‚
â”‚   â”‚     â€¢ Parts in ascending order                           â”‚  â”‚
â”‚   â”‚     â€¢ All parts >= 5MB (except last)                     â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  3. SERVER-SIDE ASSEMBLY:                                â”‚  â”‚
â”‚   â”‚     â€¢ Concatenates parts into single object              â”‚  â”‚
â”‚   â”‚     â€¢ Uses internal pointers (NOT byte copying!)        â”‚  â”‚
â”‚   â”‚     â€¢ NO data re-upload required!                        â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  4. Creates final object at s3://bucket/key              â”‚  â”‚
â”‚   â”‚  5. Deletes temporary parts storage                      â”‚  â”‚
â”‚   â”‚  6. Returns final ETag: "abc123-4" (4 = part count)      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   SERVER-SIDE ASSEMBLY (No Re-Upload!):                         â”‚
â”‚                                                                  â”‚
â”‚     [Part 1: 10MB] â”€â”                                            â”‚
â”‚     [Part 2: 10MB] â”€â”¼â”€â”€â–¶ [Final Object: 35MB]                   â”‚
â”‚     [Part 3: 10MB] â”€â”¤    s3://bucket/video.mp4                  â”‚
â”‚     [Part 4: 5MB]  â”€â”˜    ETag: "xyz789-4"                       â”‚
â”‚                                â–²                                 â”‚
â”‚                                â”‚                                 â”‚
â”‚                          "-4" = 4 parts                          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš ï¸ S3 CONSTRAINTS

### Critical Limits to Know

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              S3 MULTIPART UPLOAD CONSTRAINTS                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚   â”‚ Part Size   â”‚ Part Count  â”‚ Object Size â”‚ Additional      â”‚â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚   â”‚ MIN: 5 MB   â”‚ MIN: 1      â”‚ MAX: 5 TB   â”‚ UploadId never  â”‚â”‚
â”‚   â”‚ MAX: 5 GB   â”‚ MAX: 10,000 â”‚ = 5GBÃ—10K   â”‚ expires (until  â”‚â”‚
â”‚   â”‚ Last: any   â”‚ Ascending   â”‚             â”‚ complete/abort) â”‚â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                  â”‚
â”‚   PRACTICAL RECOMMENDATIONS:                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  â€¢ Part size: 10-100MB (balance between retries & speed) â”‚  â”‚
â”‚   â”‚  â€¢ Concurrency: 4-10 parallel uploads                    â”‚  â”‚
â”‚   â”‚  â€¢ Presigned URL expiry: 1 hour (configurable)           â”‚  â”‚
â”‚   â”‚  â€¢ Retry with exponential backoff                        â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   PART SIZE TRADE-OFFS:                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Small parts (5-10MB):                                   â”‚  â”‚
â”‚   â”‚    âœ… Fast retry on failure (less data to re-upload)    â”‚  â”‚
â”‚   â”‚    âŒ More HTTP overhead                                 â”‚  â”‚
â”‚   â”‚    âŒ More presigned URLs to generate                    â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  Large parts (50-100MB):                                 â”‚  â”‚
â”‚   â”‚    âœ… Less HTTP overhead                                 â”‚  â”‚
â”‚   â”‚    âœ… Fewer parts to manage                              â”‚  â”‚
â”‚   â”‚    âŒ Slow retry on failure                              â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš¨ FAILURE HANDLING

### What Can Go Wrong (And How to Fix It)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FAILURE SCENARIOS & SOLUTIONS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   SCENARIO 1: Part Upload Fails                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Problem: Network drops during part 5 upload             â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  Solution:                                               â”‚  â”‚
â”‚   â”‚  â€¢ Retry with exponential backoff                        â”‚  â”‚
â”‚   â”‚  â€¢ Same presigned URL still valid (within expiry)        â”‚  â”‚
â”‚   â”‚  â€¢ Only re-upload part 5, not entire file!               â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   SCENARIO 2: Client Crashes Mid-Upload                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Problem: App crashes at 80% completion                  â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  Solution:                                               â”‚  â”‚
â”‚   â”‚  â€¢ Store {uploadId, completedParts} in localStorage      â”‚  â”‚
â”‚   â”‚  â€¢ On restart, call ListParts API to verify              â”‚  â”‚
â”‚   â”‚  â€¢ Resume from where you left off                        â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   SCENARIO 3: Incomplete Uploads (COST DANGER!)                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Problem: Upload started but never completed             â”‚  â”‚
â”‚   â”‚           Parts remain in S3, INCURRING CHARGES!         â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  Solutions:                                              â”‚  â”‚
â”‚   â”‚  1. AbortMultipartUpload API - Manual cleanup            â”‚  â”‚
â”‚   â”‚  2. S3 Lifecycle Rule - Auto-abort after N days:         â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚     {                                                    â”‚  â”‚
â”‚   â”‚       "Rules": [{                                        â”‚  â”‚
â”‚   â”‚         "Status": "Enabled",                             â”‚  â”‚
â”‚   â”‚         "AbortIncompleteMultipartUpload": {              â”‚  â”‚
â”‚   â”‚           "DaysAfterInitiation": 7                       â”‚  â”‚
â”‚   â”‚         }                                                â”‚  â”‚
â”‚   â”‚       }]                                                 â”‚  â”‚
â”‚   â”‚     }                                                    â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  âš ï¸  CRITICAL: Always set lifecycle rule in production! â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   SCENARIO 4: ETag Mismatch                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Problem: Part corrupted during upload                   â”‚  â”‚
â”‚   â”‚           ETag stored by client â‰  ETag stored by S3     â”‚  â”‚
â”‚   â”‚                                                          â”‚  â”‚
â”‚   â”‚  Solution:                                               â”‚  â”‚
â”‚   â”‚  â€¢ CompleteMultipartUpload will FAIL                     â”‚  â”‚
â”‚   â”‚  â€¢ Re-upload corrupted part                              â”‚  â”‚
â”‚   â”‚  â€¢ S3's integrity check protects against corruption      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Abort Incomplete Upload

```java
// Cleanup incomplete uploads
@DeleteMapping("/api/upload/abort")
public void abortUpload(@RequestBody AbortRequest request) {
    AbortMultipartUploadRequest abortRequest = AbortMultipartUploadRequest.builder()
        .bucket(bucketName)
        .key(request.getKey())
        .uploadId(request.getUploadId())
        .build();
    
    s3Client.abortMultipartUpload(abortRequest);
    // All parts for this uploadId are deleted
    // No storage charges after abort
}
```

---

## ğŸ“Š REAL-WORLD USE CASES

### Who Uses This Pattern?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COMPANIES USING S3 MULTIPART UPLOAD                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   DROPBOX                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  â€¢ 2+ billion files synced daily                         â”‚  â”‚
â”‚   â”‚  â€¢ Max file size: 2GB (web), 50GB (desktop)             â”‚  â”‚
â”‚   â”‚  â€¢ Uses chunked upload with deduplication                â”‚  â”‚
â”‚   â”‚  â€¢ Resume interrupted uploads                            â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   NETFLIX                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  â€¢ 4K HDR content: 20-50GB per movie                     â”‚  â”‚
â”‚   â”‚  â€¢ Multiple bitrate versions: 100GB+ total per title    â”‚  â”‚
â”‚   â”‚  â€¢ Global CDN population from S3 origin                  â”‚  â”‚
â”‚   â”‚  â€¢ Parallel regional uploads                             â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   YOUTUBE                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  â€¢ 500+ hours uploaded every minute                      â”‚  â”‚
â”‚   â”‚  â€¢ Max upload: 256GB or 12 hours                        â”‚  â”‚
â”‚   â”‚  â€¢ Resumable uploads for reliability                     â”‚  â”‚
â”‚   â”‚  â€¢ Background processing while uploading                 â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚   GOOGLE DRIVE                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  â€¢ Max file size: 5TB (matches S3 limit!)               â”‚  â”‚
â”‚   â”‚  â€¢ Resumable uploads API                                 â”‚  â”‚
â”‚   â”‚  â€¢ Automatic retry on failure                            â”‚  â”‚
â”‚   â”‚  â€¢ Cross-platform sync                                   â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ USEFUL S3 APIs

### APIs for Managing Multipart Uploads

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              S3 MULTIPART UPLOAD APIs                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   CreateMultipartUpload                                          â”‚
â”‚   POST /bucket/key?uploads                                       â”‚
â”‚   â†’ Returns: UploadId                                            â”‚
â”‚                                                                  â”‚
â”‚   UploadPart                                                     â”‚
â”‚   PUT /bucket/key?partNumber=N&uploadId=xyz                     â”‚
â”‚   â†’ Returns: ETag                                                â”‚
â”‚                                                                  â”‚
â”‚   ListParts (for resuming)                                       â”‚
â”‚   GET /bucket/key?uploadId=xyz                                   â”‚
â”‚   â†’ Returns: [{PartNumber, ETag, Size, LastModified}]           â”‚
â”‚                                                                  â”‚
â”‚   ListMultipartUploads (for cleanup monitoring)                  â”‚
â”‚   GET /bucket?uploads                                            â”‚
â”‚   â†’ Returns: All incomplete uploads in bucket                    â”‚
â”‚                                                                  â”‚
â”‚   CompleteMultipartUpload                                        â”‚
â”‚   POST /bucket/key?uploadId=xyz                                  â”‚
â”‚   Body: Ordered list of {PartNumber, ETag}                      â”‚
â”‚   â†’ Returns: Final object location, ETag                        â”‚
â”‚                                                                  â”‚
â”‚   AbortMultipartUpload                                           â”‚
â”‚   DELETE /bucket/key?uploadId=xyz                                â”‚
â”‚   â†’ Deletes all parts, stops charges                            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ KEY ARCHITECTURAL INSIGHTS

### Why This Pattern Works

| Insight | Benefit |
|---------|---------|
| **Backend never sees file data** | Infinitely scalable, no memory issues |
| **Presigned URLs** | Secure, no credential exposure |
| **Parallel uploads** | 4-10x faster than sequential |
| **Server-side assembly** | No re-upload, S3 handles concatenation |
| **ETag verification** | Data integrity guaranteed |
| **Resumable** | Network failures don't lose progress |

---

## â“ Interview Practice

### Question 1:
> "How would you design a file upload system that handles 5TB files?"

**Answer:**
> "I'd use S3 Multipart Upload with a hybrid architecture. The backend generates presigned URLs (for security) and the client uploads directly to S3 (for scalability). Files are split into 10-100MB chunks, uploaded in parallel (4-10 concurrent), and S3 assembles them server-side. This means the backend never sees file data, making it infinitely scalable. I'd add retry logic with exponential backoff, store progress in localStorage for resume capability, and set S3 lifecycle rules to auto-abort incomplete uploads after 7 days."

### Question 2:
> "Why use presigned URLs instead of proxying through the backend?"

**Answer:**
> "Two reasons: security and scalability. Exposing AWS credentials to the client is a security disaster. Proxying through the backend means every byte of every file flows through your servers - for a 5TB file, that's unsustainable. Presigned URLs give clients time-limited, operation-specific access to S3 directly. The backend handles metadata only, making it stateless and horizontally scalable. The actual file data goes client-to-S3 directly."

### Question 3:
> "What happens if a part upload fails at 80%?"

**Answer:**
> "Only that one part needs to be re-uploaded, not the entire file. The presigned URL is still valid within its expiry window. We implement retry with exponential backoff - wait 1s, 2s, 4s between attempts. If the client crashes completely, we store uploadId and completed parts in localStorage. On restart, we call S3's ListParts API to verify which parts are already uploaded, then resume from there. The key insight is that S3 keeps partial uploads indefinitely until we call Complete or Abort."

---

## ğŸ”— Connecting to Previous Days

| Day | Concept | How It Connects |
|-----|---------|-----------------|
| Day 15 | Redis Single-Threaded | Presigned URL caching |
| Day 18 | Redis Timeouts | Backend service resilience |
| Day 19 | Bloom Filters | Deduplication of uploaded chunks |

---

## âœ… Day 20 Action Items

1. **Implement a multipart uploader** with parallel chunking in your project
2. **Set up S3 Lifecycle Rules** to auto-abort incomplete uploads
3. **Add progress tracking** and resume capability
4. **Test failure scenarios** - network drops, client crashes

---

## ğŸ’¡ Key Takeaways

| Insight | Why It Matters |
|---------|----------------|
| Presigned URLs = Secure + Scalable | No credential exposure, no backend bottleneck |
| Parallel uploads | 4-10x faster than sequential |
| Server-side assembly | No re-upload after parts complete |
| ETag = MD5 hash | Integrity verification built-in |
| Lifecycle rules | Prevent cost leakage from incomplete uploads |

---

## ğŸ¯ The Architect's Principle

> **Junior:** "I'll just POST the entire file to my backend and upload to S3."
>
> **Architect:** "For a 5TB file? Your server will OOM and timeout. Instead, use presigned URLs so clients upload directly to S3. Split into 10MB chunks for parallel upload and resume capability. The backend only handles metadata - it never sees file bytes. S3 assembles parts server-side, so there's no re-upload. And always set lifecycle rules to auto-abort incomplete uploads, or you'll have mystery S3 bills from orphaned parts."

---

*â€” Sunchit Dudeja*  
*Day 20 of 50: System Design Interview Preparation Series*

---

> ğŸ¯ **Interview Edge:** When asked about large file uploads, immediately mention: "Presigned URLs for security, chunked parallel upload for speed, server-side assembly for efficiency, and lifecycle rules for cost management."

> ğŸ“¢ **Real Impact:** Dropbox uploads 2+ billion files daily using this pattern. Netflix uploads 50GB+ 4K content per title. YouTube handles 500+ hours uploaded every minute. The pattern is industry standard.

---

> ğŸ’¡ **Tomorrow (Day 21):** We'll explore **Consistent Hashing** â€” how Netflix, Discord, and Amazon distribute data across thousands of servers without rehashing everything when nodes join or leave.

